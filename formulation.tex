\section{Problem Formulation}

Define the virtual actor model, then define why we want reactive programming.

\subsection{Virtual Actors}

Actors have emerged as a useful abstraction for the middle tier of scalable service applications that run on virtualized cloud infrastructure in a datacenter [36][37][46]. In such systems, each actor is an object with a user-defined meaning, identity, state, and operations. For example, actors can represent user profiles, articles, game sessions, devices, bank accounts, or chat rooms. Actors resemble miniature servers: they do not share memory, but communicate asynchronously, and can fail and recover independently. One of the main benefit of actor systems is that they \emph{scale horizontally}, because the actor instances can be distributed across a cluster of servers.

In a traditional bare-bones actor system, the developer remains responsible for the creation, placement, discovery, recovery, and load-balancing of actors. A newer generation of actor models [4][36][37], called virtual actor models, automate all of these aspects. The developer specifies only (1) a unique key for identifying each actor, and (2) how to save and load the actor state to/from external storage, if persistence is desired. As virtual actor systems can activate and deactivate actors based on use, they strongly resemble distributed caches [14][39][40][55] and provide similar performance benefits. 

Following the terminology [4], we call the virtual actors \emph{grains}. For each grain type, the code defines a (1) key that identifies instances, (2)  fields that define the grain state, and (3) operations supported by the grain. The operations of a grain can read and modify the grain state, and can call operations on other grains, but cannot directly read or write the state of other grains (encapsulation). 
 
\subsubsection{Example: Chirper}

As a running example, we use a service called Chirper (based on the Orleans sample with the same name). It models a typical social application where users post messages to their own timeline, and view messages posted by people they are following.
The code for the chirper service (not including the chirper client) is shown in Fig.~\ref{fig:chirper}, written in an imaginary DSL (domain-specific language) to help us focus on the programming model. 

\begin{figure}
\begin{lstlisting}
grain User[userid: string] %\label{l:def}%
{
	// grain state
	state Messages: map<<time,string>>;%\label{l:msgs}%
	state Follows: set<<string>>;%\label{l:flws}%
	// update operations
	op Post(t: time, msg: string) { Messages[t] = msg; }%\label{b:uo}%
	op Unpost(t: time) { Messages.remove(t); }
	op Follow(id: string) { Follows.add(id); }
	op Unfollow(id: string) { Follows.remove(id); }%\label{e:uo}%
	// query operations
	op GetMessages(from: time) : list<<pair<<time,string>>>> { %\label{l:getm}%
		var msgs = new list<<pair<<time,string>>>>();
		foreach(var m in Messages)
			if (m.key >= from)
				msgs.add((m.key, m.value));
		return msgs;
	}
	op GetTimeline(from: time): list<<pair<<time,string>>>> {%\label{l:gettl}%
		var msgs = GetMessages(from);%\label{l:loc}%
		parallel foreach(var f in Follows) {%\label{l:par}%
			// retrieve messages from user f by remote call
			var fm = User[f].GetMessages(from); %\label{l:rcall}%
			foreach(var m in fm) { msgs.add(m); }%\label{l:add}%
		}
		msgs.sort();%\label{l:sort}%
		return msgs;%\label{l:ret}%
	}
}
\end{lstlisting}
\caption{Pseudocode for the Chirper service example.}\label{fig:chirper}
\end{figure}

There is only one type of grain, called \lstinline|User|.  A user grain encapsulates data associated with a user, and is identified by a string called \lstinline{userid} (\lref{def}). Each user grain stores the messages posted by that user in a map data structure \lstinline|Messages| (\lref{msgs}), keyed by timestamp. The current list of followed users is stored in \lstinline|Follows| (\lref{flws}). This grain state can change in response to update operations \lstinline|Post|, \lstinline|Unpost|, \lstinline|Follow|, \lstinline|Unfollow| (\rref{uo}) , which are invoked by the chirper client in response to clicking respective buttons.

The operation \lstinline|GetMessages(from)| (\lref{getm}) returns all messages by this user since the time indicated by \lstinline|from|; it straightforwardly computes the result by iterating over \lstinline{Messages}.  

The operation  \lstinline|GetTimeline(from)|  (\lref{gettl}) is more interesting. It returns a sorted list of all messages posted by the user \emph{and all followed users} since  the time indicated by \lstinline|from|. It computes the result as follows: first, it retrieves the locally stored messages (\lref{loc}). Then, \emph{in parallel} (\lref{par}), it calls \lstinline|GetMessages| on all followed users. These calls target other grains, by constructing a grain reference \lstinline|User[f]| to the grain for userid \lstinline|f| (\lref{rcall}). The returned messages are all added to the list \lstinline|msgs| (\lref{add}). After all the parallel tasks complete, the messages are sorted (\lref{sort}) and returned (\lref{ret}).

\subsubsection{Failure Model}

The virtual actor model does not hide failures: a grain may fail at any time, even when in the middle of executing an operation, and this can be observed. However, the runtime does provide some support for dealing with failures.

\paragraph{Recovering Grains.} If a grain is hosted on a server and that server fails, the runtime activates a fresh instance of the grain the next time it is accessed. 

\paragraph{Persistent Grains.} Optionally, programmers can declare grains to be \emph{persistent}, which means their state is saved in external persistent storage. The state of a persistent grain is saved after each operation that updates the state, and loaded from storage when a grain is activated. The \lstinline|User| grains in the chirper example are persistent. 

\paragraph{Automatic Timeouts.} All grain operations throw a special timeout-exception if no response is received after a configurable time limit (the default is 30 seconds). This helps to avoid hangs and deadlocks if a grain fails before responding, or becomes unavailable for other reasons.

If an operation times out, the caller does not know whether its effect was performed or not. To handle this issue, applications often design update operations to be \emph{idempotent} \cite{kapil}, so they can be safely retried after encountering a timeout-exception. For example, all the operations of the \lstinline|User| grain in Fig.~\ref{fig:chirper} are idempotent.

\hidden{

\subsection{Runtime Implementation}

Under the hood, the runtime must provide the needed distributed protocols for managing the creation, placement, discovery, recovery, and load-balancing of actors. By design, the application layer is largely unaware of how these details. Nevertheless, we briefly describe the mechanisms used by the Orleans system here. 

\paragraph{Grain Directory}. Grains can be active (there exists an instance of it on some machine) or inactive (otherwise). The runtime maintains a distributed directory (based on the consistent hashing algorithm)  for tracking active grains. When an inactive grain is accessed, the runtime automatically activates it, and places it on a randomly selected server. If a grain is not accessed for a prolonged (configurable) time, it is deactivated and removed from the grain directory. 

\paragraph{Silo Failures}. Under the hood, the runtime tracks all participating servers, called \emph{silos}, using a membership protocol. The set of members can change when administrators choose to increase or decrease the number of servers, or when servers fail, which is detected automatically.  For \emph{volatile} grains, the grain state is lost on failure. For \emph{persistent} grains, the grain state is saved to persistent storage after each change, and loaded from persistent storage when activated. 
 

The actual C\# code is similar, but contains more detail and uses language features that are not highly relevant in this context, albeit interesting in their own right (e.g. LINQ expressions, cooperative concurrency with async-await).
}

\subsection{Reactivity}

Suppose now that we want our chirper client to not just display a frozen snapshot of the timeline, but to react to changes in the application state and refresh the user interface accordingly. What are our implementation options? 

\begin{figure}
\begin{lstlisting}
while (interested) {
	try {
		var result = Grain[myuserid].GetTimeline();
		display(result);
	} catch(TimeoutException) {  } // ignore this exception
	await delay(5000); // wait for 5 seconds
}
\end{lstlisting}
\caption{Solution using client-side polling.}\label{fig:polling}
\end{figure}

\paragraph{Client-side Polling. } A straightforward solution is to have the client repeat the query periodically to retrieve the latest state (Fig.\ref{fig:polling}). This solution is easy to understand, requires no changes to the service code, and gracefully handles transient exceptions (e.g. when requests time out under high load, or when one of the grains fails). However, it confronts us with a unpleasant tradeoff when selecting the \textbf{polling interval}: if \emph{long}, the displayed result may lag significantly behind the current result; if \emph{short}, we increase the load on our service and thus have to pay for more servers. We demonstrate this tradeoff experimentally in section \ref{sec:evaluation} .

\begin{figure}
\begin{lstlisting}
// new additions to  grain state
state Observers: map<<Observer,time>>; 
state Followers: set<<userid>>; 	
// new update operations
op AddFollower (userid: string)
	{ Followers.Add(userid); }
op RemoveFollower (userid: string)
	{ Followers.Remove(userid); }
op AddObserver (client: Observer, from: time)
   : list<<pair<<time,string>>>>{%\label{l:cs}%
 	Observers[client] = time; 
 	return GetTimeline(from);
}
op RemoveObserver (client: Observer)
	{ Observers.Remove(client); }
// modifications to existing update operations
op Post(tstamp: time, msg: string) { 
	...
	NotifyFollowers();  NotifyObservers();
} 
op Unpost(tstamp: time) { 
	...
	NotifyFollowers();  NotifyObservers();
}
op Follow(userid: string) {  
	... 
	User[userid].AddFollower(this.userid);
	NotifyObservers();
}
op Unfollow(userid: string) { 
	...  
	User[userid].RemoveFollower(this.userid);
	NotifyObservers(); 
}
// new propagation operations
op NotifyObservers() {
	foreach(var (client,from) in Observers) {
		var latest = GetTimeline(from);
		client.Notify(latest);
	}
}
op NotifyFollowers() {
	parallel foreach(var f in Followers) { f.NotifyObservers(); }
}
\end{lstlisting}
\caption{Cautionary sketch of what it may take to apply the observer pattern to the \lstinline|User| grain from Fig.~\ref{fig:chirper}.}\label{fig:observers}
\end{figure}

\paragraph{Observer Pattern.} To achieve better performance, we may consider implementing change propagation at the application level.  This is not very simple: we sketch how one may apply the observer pattern to the \lstinline|User| grain in Fig.~\ref{fig:observer}. User grains now track observing clients and followers. Clients can register themselves as observers (\lref{cs}), which means they receive notifications containing the latest result. \emph{But this design leaves much to be desired. } We have polluted the grain state with information about observers, and it is unclear whether this state should be persisted (and thereby pollute our storage as well) or not (and thereby cause issues when grains fail). Moreover, changes are not propagated selectively: a change notification forces the client to reexecute the entire query, even if only a small part of the computation is different.

\hidden
{\begin{itemize}
\item It is not clear if the client observers should be considered part of the normal grain state and persisted along with it. If observer lists are not persisted, they are lost on failures - but if they are persisted, we pay a performance price.
\item We are now saving redundant information in the user grains (\lstinline{Follows} and \lstinline{Followers} represent the same relation), and can observe inconsistencies  (the state of multiple grains is not saved atomically).  
\item Changes are not propagated selectively: a change notification forces the client to reexecute the entire query, even if only a small part of the computation is different.
\end{itemize}
}

\hidden{
Conceivably, a skilled programmer can solve all of these issues at the application level --- but in our experience, this is a road that leads to complex, error-prone code that is susceptible to deadlocks and subtle race conditions. There is a better way.
}

\subsection{Proposed Solution}

It turns out that it is in fact possible to retain the elegant simplicity and well-defined failure handling of the client-side polling solution (Fig.\ref{}) while performing efficient dependency tracking and reactive change propagation \emph{under the hood}, fully automatically. The reason is that the virtual actor model already provides us with a clean decomposition of computations and clear interception points (grain calls) that can be cached (memoized) and updated reactively. 





with the performance of a reactive implementation that pushes changes only where necessary and can avoid unnecessary re-execution of unaffected subcomputations. Perhaps surprisingly, the answer is yes.

\begin{figure}
\begin{lstlisting}
	var rc = CreateReactiveComputation(
		() =>  Grain[myuserid].GetTimeline()
	);
	var resulttracker = rc.GetResultTracker();
	try {
	 	while (interested) 
	 		try {
				var result = await resulttracker.NextResult();
				display(result);
			} catch(TimeoutException) {  }
	} finally {
		rc.Dispose();
	}
}
\end{lstlisting}
\caption{Proposed solution: runtime support for reactive computations.}\label{fig:chirper}
\end{figure}



