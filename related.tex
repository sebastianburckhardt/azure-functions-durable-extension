\section{Related Work}

As discussed in the introduction, reactive programming is a rich area of research that spans language design, algorithms and implementation architecture (see the survey \cite{reactivesurvey}).

A primary difference between our solution and much prior work on FRP \cite{frp-firstprinciples,frp-animation,frp-frtime,frp-arrows,elm,afp,flapjax,frappe} is that our computations do not require the addition of special operators/combinators to the host language, but execute just like regular code (imperative, object-oriented C\# in our case). This reduces the mental overhead for programmers who are unfamiliar with FRP, or in situations where the FRP operators lack expressiveness. Incrementality is not achieved via compilation, but at runtime: the trick is to decompose the computation into subcomputations that can be selectively re-evaluated if their dependencies change. This is the principle used by self-adjusting computation \cite{acar-ahmed-blume-POPL08,Acar:SelfAdjustingExperiments,Acar:SelfAdjustingOverview,Hammer:Ceal09,Acar:SelfAdjustingTypes10}, one-way dataflow constraints \cite{camil}, or incremental concurrent revisions \cite{burckhardt-leijen-yi-sadowski-ball-OOPSLA11}. The difference is that here, we use the encapsulation afforded by the \emph{actor model} as a means to decompose the computation.

Reactive techniques also apply to large-scale data-parallel computations used for data analytics \cite{mapreduce,spark}. Some systems can automatically incrementalize mapreduce queries\cite{mronline,incoop} or queries constructed from a FRP-like vocabulary of operators \cite{nectar}, possibly including fixpoints \cite{frank}. Frameworks for stream programming \cite{flink} have also gained popularity - they are more low-level and very flexible, as the user assumes responsibility for plumbing the streams together to achieve the desired effect. Just as for our elastic services, fault tolerance is crucial for all of those systems. However, the workload is quite different. Our reactive computations do not exploit data-parallelism over massive data sets, but provide fine-grained concurrency for virtual actors.

\hidden{
Change propagation is semantically subtle. In synchronous models, time is explicit. Asynchronous models may make strong consistency guarantees based on some form of version tracking, or may have weaker consistency guarantees. For example, a so-called glitch means that an observer sees two observables A, B that have inconsistent state, meaning that the set of updates propagated to A is different from the set of updates propagated to B. Many reactive systems strive to eliminate glitches (e.g. using topological ordering of dependencies), but some embrace them.
}

At the other end of the spectrum are synchronous reactive languages \cite{lustre,signal,esterel,syncdataflow}, where time is explicit, and systems make very strong semantic guarantees. It is hard to imagine an efficient implementation of such models in the context of a scalable service built from asynchronously communicating independent actors, given the high cost of coordination. Because actors can be modified independently on different machines, our applications are \emph{exochronous} (multiple inputs to the dependency graph) as opposed to \emph{endochronous}.  

The problem of combining object-oriented and reactive paradigms is not new \cite{Salvaneschi:2013:RBO:2451436.2451442}, as there is often a desire to connect object-oriented GUI frameworks with functional-reactive backends \cite{statelines}. In some sense our problem is the exact opposite: adding reactivity to an object-oriented (or rather, actor) back-end to support a reactive user interface.  SuperGlue \cite{superglue} is another example that adds reactivity to objects. In our experience, actor models provide a much better home for reactivity than mainstream object-oriented programs, because actors completely prevent the passing of shared data structures as arguments and return values. Our dependency tracking algorithm crucially relies on this fact when computing and caching summaries.


Clearly, how to best balance consistency and performance is highly dependent on the architecture and workload. 
Avoiding glitches in a distributed actor system like ours is likely to add significant latency overhead: updates are only partially ordered to begin with, and dependencies are detected dynamically. Also, for the applications we have in mind, it is typically preferrable to temporarily display a glitchy result and then quickly correct it, than to generally wait longer. Consequently, we chose an algorithm that does not avoid glitches or causality violations categorically, but guarantees that they are ephemeral (\S\ref{sec:cp}). This tradeoff is quite similar to the variations of eventual consistency \cite{principles}.
 


\hidden{
\subsection{Expressing Views.} Often, views can observe other views, creating a directed acyclic graph of dependencies. How to express such dependency graphs using recursive operators is a key question in the area of dataflow languages, functional reactive programming, and object-oriented frameworks such as Rx. In relational database systems, views are expressed by relational queries (which allows changes to be propagated incrementally). in Facebook's react.js, the application state is observed by a tree-structured virtual DOM, which is in turn observed by the browser's DOM. And in relational database systems, views are expressed by relational queries (which allows changes to be propagated incrementally)

 }


 


% These are just paragraphs of information about certain topics, still needs to be put in a nice text if they are used %


% RP %
\paragraph{General purpose FRP models} \cite{reactivesurvey} require you to write down your program in terms of signals and behaviours, i.e. explicitly write down the dependencies. Furthermore, while still a lot of research is being conducted to efficiently perform glitch-free propagation cycles on a single node, lately some initial research is being performed to do this in a distributed setting \cite{elm}\cite{drescala}. Even though future research might solve this, it is still an open research question on how to maintain a distributed propagation algorithm that can handle dynamic dependency graphs and doesn't require a central coordinator. Yet, these two properties are essential to providing scalable services, since topologies change, nodes fail and coordination is too costly.

The presented model in this paper is very different in the sense that (1) the programmer is not required to explicitly provide the dependency graph using special constructs/types, allowing snapshot and reactive behaviour from the exact same code base, and (2) it allows executions that observe a glitch, yet, it does guarantee that it will eventually perform a glitch-free execution. As a result, this algorithm naturally lends itself more towards large-scale, fault-tolerant systems, by sacrificing some consistency guarantees. At the same time it demands less from the programmer. \newline


%% More info on distributed FRP %%
\paragraph{motivation against distributed reactive FRP for the statement in the introduction}
Citations straight from \cite{drescala}:

\emph{We propose Distributed REScala, a reactive language
with a change propagation algorithm that works without
centralized knowledge about the topology of the dependency
structure among reactive values and avoids unnecessary
propagation of changes, while retaining safety guarantees
(glitch freedom).}

The ``centralized knowledge of the topology of the dependency structure'' is very important here. This doesn't mean they don't need a central coordinator, because then on page 7 you can find the crux of why I think the algorithm is being oversold:

\emph{Update turns in SID-UP must happen mutually exclusive:
Concurrent updates may cause glitches by exposing partial
results to each other whenever they affect the same node in
the DG. If this can not be guaranteed by the nature of the
application, a centralized coordinator is needed during the
admission phase. Every thread that wants to admit a change
must first contact this coordinator to acquire exclusive access
to execute an update turn. After the turn completes, the
exclusive access is relinquished to allow the next update turn
to start. These are the only two messages outside of regular
pulses in SID-UP and they require many-to-one communication
only. Supporting concurrent update turns, thus getting
rid of the centralized coordination, is ongoing work.} \newline

And this is from the conclusion:
\emph{There are several areas for future work. We plan to extend
our approach to support concurrent update turns and to handle
failures.}\newline


% Big Data %
\paragraph{Big data processing/analytics models.} Two types: (1) batch processing (Spark, Hadoop) \cite{mapreduce} and (2) stream processing (Apache Flink \& Storm). Can be seen as a  distributed FRP model, because it uses functional operators over sets of distributed data. Batch processing assumes the data doesn't change and stream processing is able to handle continuously changing data. They have the same drawback as any FRP, in that they require special purpose types and functions.


\paragraph{Dataflow (Synchronous) Languages}
\cite{syncdataflow}
The main idea is that they describe, and formalize, dataflow sychronous languages and categorize two important types of applications w.r.t. asynchronous environments: "exochronous" and "endochronous". Exochronous applications can have multiple inputs to the dependency graph, while endochronous only have one. As a consequence, synchronous endochronous applications can be easily compiled into an asynchronous setting, i.e. distributed application, without coordination. Exochronous applications on the other hand require a coordinator when distributed. \newline
We clearly support asynchronous exochronous applications without coordination.

Haven't read this paper very well, but one of my friends at the lab his paper about a distributed reactive propagation algorithm got rejected because he did not mention it...
It's a pretty terse paper, but if you're interested, the crux about the compilation to asynchronous environments is on page 141 (or 17 in de pdf), it's in the related folder. I'm not sure if and how we should incorporate this though. \newline


\cite{lustre}\cite{signal} In general synchronous dataflow languages are aimed towards applications with bounded memory and real-time constraints. In multi-clock Esterel\cite{esterel} different parts of the program are no longer bound to the global clock though. This means that we could possibly run different parts of the reactive program in a distributed setting. Nevertheless, the model assumes instantaneous communication between the parts running on different clocks and clock ticks happen mutually exclusive. This inherently makes it a bad fit for implementing scalable distributed services.


\cite{orleans}
