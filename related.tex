\section{Related Work}

As discussed in the introduction, reactive programming is a rich area of research that spans language design, algorithms and implementation architecture (see the survey \cite{reactivesurvey}).

A main difference between our solution and much prior work on FRP \cite{frp-firstprinciples,frp-animation,frp-frtime,elm,afp} is that our computations are not expressed using a set of operators/combinators supported by the compiler, but execute like regular code of the host language (imperative, object-oriented C\#). Incrementality is achieved at runtime, by decomposing the computation into subcomputations at that can be selectively re-evaluated if their dependencies change. In that sense, our solution follows the same principle as self-adjusting computation \cite{acar-ahmed-blume-POPL08,Acar:SelfAdjustingExperiments,Acar:SelfAdjustingOverview,Hammer:Ceal09,Acar:SelfAdjustingTypes10}, one-way dataflow constraints \cite{camil}, or incremental concurrent revisions \cite{burckhardt-leijen-yi-sadowski-ball-OOPSLA11}, except that here, we use the encapsulation afforded by the actor model as a means to decompose the computation.


Change propagation is semantically subtle. In sychronous models, time is explicit. Asynchronous models may make strong consistency guarantees based on some form of version tracking, or may have weaker consistency guarantees. For example, a so-called glitch means that an observer sees two observables A, B that have inconsistent state, meaning that the set of updates propagated to A is different from the set of updates propagated to B. Many reactive systems strive to eliminate glitches (e.g. using topological ordering of dependencies), but some embrace them.

Clearly, how to best balance consistency and performance is highly dependent on the architecture and workload. 
avoiding glitches in a distributed actor system like ours is likely to add significant latency overhead: updates are only partially ordered to begin with, and dependencies are detected dynamically. Also, for the applications we have in mind, it is typically preferrable to quickly display a glitchy result and then quickly correct it, than to generally wait longer. Consequently, we chose an algorithm that does not avoid glitches or causality violations categorically, but guarantees that they are ephemeral (\S\ref{sec:cp}). This tradeoff is quite similar to the variations of eventual consistency.
 

\subsection{Expressing Views.} Often, views can observe other views, creating a directed acyclic graph of dependencies. How to express such dependency graphs using recursive operators is a key question in the area of dataflow languages, functional reactive programming, and object-oriented frameworks such as Rx. In relational database systems, views are expressed by relational queries (which allows changes to be propagated incrementally). in Facebook's react.js, the application state is observed by a tree-structured virtual DOM, which is in turn observed by the browser's DOM. And in relational database systems, views are expressed by relational queries (which allows changes to be propagated incrementally)

 


 
 
\cite{burckhardt-leijen-yi-sadowski-ball-OOPSLA11}
\cite{camil}


\cite{alive}
\cite{react}

\cite{elm} language for gui construction

\cite{statelines} inverse problem

% These are just paragraphs of information about certain topics, still needs to be put in a nice text if they are used %



General purpose FRP models \cite{reactivesurvey} require you to write down your program in terms of signals and behaviours, i.e. explicitly writing down the dependency graph. Furthermore, while still a lot of research is being conducted to efficiently perform glitch-free propagation cycles on a single node, lately some initial research is being performed to do this in a distributed setting \cite{elm}\cite{drescala}. Even though we believe future research might solve this, right now it is tremendously difficult to create a distributed propagation algorithm that can handle dynamic dependency graphs and doesn't require a central coordinator. The presented model in this paper is very different in that sense, because it allows executions that observe a glitch. Yet, it does guarantee that it will eventually perform a glitch-free execution. As a result, this algorithm naturally lends itself more towards large-scale, fault-tolerant systems, by sacrificing some consistency guarantees.


Big data processing/analytics models: (1) batch processing (Spark, Hadoop) \cite{mapreduce} and (2) stream processing (Apache Flink \& Storm). Can be seen as a  distributed FRP model, because it uses functional operators over sets of distributed data. Batch processing assumes the data doesn't change and stream processing is able to handle continuously changing data. They have the same drawback as any FRP, in that they require special purpose types and functions.

\cite{orleans}
