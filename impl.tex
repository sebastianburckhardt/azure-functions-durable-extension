\section{Implementation} \label{sec:implementation}

We have implemented reactive computations as extensions to Orleans, an open-source distributed actor framework for .NET available on GitHub ["37"]. The Orleans runtime already provides the needed distributed protocols for managing the creation, placement, discovery, recovery, and load-balancing of grains. What we added is (a) extensions to the grain objects to store summaries, (b) interception points for grain calls, (b) modifications to the grain scheduler to distinguish between reactive and normal execution mode, and (c) a silo-wide cache manager. 

In an object-oriented imperative language like C\#, we cannot statically determine whether a grain operation modifies the grain state. Thus, we conservatively trigger change propagation after \emph{any} operation on a grain. This is not as expensive as it may seem at first, because if the grain state has not changed, re-execution of the summary produces the same result, and propagation stops. Still, the programmer can annotate an operation as read-only to avoid this overhead; also, we assume that any operation called as part of a reactive computation does not change the grain state, and avoid summary re-execution in that case.

\hidden
{
\subsection{Runtime Implementation}

Under the hood, the runtime must provide the needed distributed protocols for managing the creation, placement, discovery, recovery, and load-balancing of actors. By design, the application layer is largely unaware of how these details. Nevertheless, we briefly describe the mechanisms used by the Orleans system here. 

\mypar{Grain Directory} Grains can be active (there exists an instance of it on some machine) or inactive (otherwise). The runtime maintains a distributed directory (based on the consistent hashing algorithm)  for tracking active grains. When an inactive grain is accessed, the runtime automatically activates it, and places it on a randomly selected server. If a grain is not accessed for a prolonged (configurable) time, it is deactivated and removed from the grain directory. 

\mypar{Silo Failures} Under the hood, the runtime tracks all participating servers, called \emph{silos}, using a membership protocol. The set of members can change when administrators choose to increase or decrease the number of servers, or when servers fail, which is detected automatically.  For \emph{volatile} grains, the grain state is lost on failure. For \emph{persistent} grains, the grain state is saved to persistent storage after each change, and loaded from persistent storage when activated. 
 

--- The actual C\# code is similar, but contains more detail and uses language features that are not highly relevant in this context, albeit interesting in their own right (e.g. LINQ expressions, cooperative concurrency with async-await).

--- ResultTrackers have some interesting properties that make them well suited for situations where updating the display requires I/O, such as when communicating with a remotely connected client device:   (1) result trackers may skip intermediate versions: only the latest result matters, and (2) result trackers return a task that can be efficiently awaited without blocking the thread (using C\# language support for async/await \cite{Bierman2012}).  Also, it is possible to use multiple result trackers for the same reactive computation, and each one can consume results at its own speed.

--- reactive computations available on silo or client
}

